{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPMEgwIO89UhxF6GAD/fQY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manudrel/Reconhecimento-Facial/blob/main/Reconhecimento_facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPLICAÇÃO**\n",
        "Foi utilizado como base para habilitar a webcam no Google Colab o NoteBook disponiblizado pelo The AI Guy no vídeo: How to Use Webcam In Google Colab for Images and Video (FACE DETECTION)\n",
        "\n",
        "[Link do Colab do The AI Guy](https://colab.research.google.com/drive/1QnC7lV7oVFk5OZCm75fqbLAfD9qBy9bw?usp=sharing)\n",
        "---"
      ],
      "metadata": {
        "id": "ht_XKX2Q0M4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import das Dependencias**"
      ],
      "metadata": {
        "id": "o-GH3WiqiUwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir3tAGOPvky-"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from contextlib import contextmanager, redirect_stdout, redirect_stderr\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "B6u0euj0dgO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte da Câmera — Funções básicas**\n",
        "Esta seção é responsável por habilitar a webcam no Google Colab e preparar o ambiente para capturar imagens em tempo real.\n",
        "---"
      ],
      "metadata": {
        "id": "Gqzhb7evhX1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_html = \"\"\"\n",
        "<video id=\"video\" width=640 height=480 autoplay muted></video>\n",
        "<canvas id=\"canvas\" width=640 height=480 style=\"position:absolute;top:0;left:0;\"></canvas>\n",
        "<script>\n",
        "var video = document.getElementById('video');\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(function(stream) {\n",
        "    video.srcObject = stream;\n",
        "    video.play();\n",
        "  });\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(video_html))"
      ],
      "metadata": {
        "id": "OVDvzhMmy00o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def bbox_to_bytes(bbox_array):\n",
        "    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    bbox_PIL.save(iobuf, format='png')\n",
        "    bbox_bytes = 'data:image/png;base64,{}'.format(\n",
        "        str(b64encode(iobuf.getvalue()), 'utf-8'))\n",
        "    return bbox_bytes\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "    data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "jVCipyMYf1Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_stream():\n",
        "    display(Javascript('''\n",
        "        var video;\n",
        "        var div = null;\n",
        "        var stream;\n",
        "        var captureCanvas;\n",
        "        var imgElement;\n",
        "        var labelElement;\n",
        "        var pendingResolve = null;\n",
        "        var shutdown = false;\n",
        "\n",
        "        function removeDom() {\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            div.remove();\n",
        "            video = null;\n",
        "            div = null;\n",
        "            stream = null;\n",
        "            imgElement = null;\n",
        "            captureCanvas = null;\n",
        "            labelElement = null;\n",
        "        }\n",
        "\n",
        "        function onAnimationFrame() {\n",
        "            if (!shutdown) {\n",
        "                window.requestAnimationFrame(onAnimationFrame);\n",
        "            }\n",
        "            if (pendingResolve) {\n",
        "                var result = \"\";\n",
        "                if (!shutdown) {\n",
        "                    captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "                    result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "                }\n",
        "                var lp = pendingResolve;\n",
        "                pendingResolve = null;\n",
        "                lp(result);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function createDom() {\n",
        "            if (div !== null) return stream;\n",
        "\n",
        "            div = document.createElement('div');\n",
        "            div.style.border = '2px solid black';\n",
        "            div.style.padding = '3px';\n",
        "            div.style.width = '100%';\n",
        "            div.style.maxWidth = '600px';\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            const modelOut = document.createElement('div');\n",
        "            modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "            labelElement = document.createElement('span');\n",
        "            labelElement.innerText = 'No data';\n",
        "            labelElement.style.fontWeight = 'bold';\n",
        "            modelOut.appendChild(labelElement);\n",
        "            div.appendChild(modelOut);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            video.width = div.clientWidth - 6;\n",
        "            video.setAttribute('playsinline', '');\n",
        "            video.onclick = () => { shutdown = true; };\n",
        "            stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"user\"}});\n",
        "            div.appendChild(video);\n",
        "\n",
        "            imgElement = document.createElement('img');\n",
        "            imgElement.style.position = 'absolute';\n",
        "            imgElement.style.zIndex = 1;\n",
        "            imgElement.onclick = () => { shutdown = true; };\n",
        "            div.appendChild(imgElement);\n",
        "\n",
        "            const instruction = document.createElement('div');\n",
        "            instruction.innerHTML = '<span style=\"color: red; font-weight: bold;\">Clique para parar</span>';\n",
        "            div.appendChild(instruction);\n",
        "            instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            captureCanvas = document.createElement('canvas');\n",
        "            captureCanvas.width = 640;\n",
        "            captureCanvas.height = 480;\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "            return stream;\n",
        "        }\n",
        "\n",
        "        async function stream_frame(label, imgData) {\n",
        "            if (shutdown) {\n",
        "                removeDom();\n",
        "                shutdown = false;\n",
        "                return '';\n",
        "            }\n",
        "\n",
        "            stream = await createDom();\n",
        "\n",
        "            if (label != \"\") {\n",
        "                labelElement.innerHTML = label;\n",
        "            }\n",
        "\n",
        "            if (imgData != \"\") {\n",
        "                var videoRect = video.getClientRects()[0];\n",
        "                imgElement.style.top = videoRect.top + \"px\";\n",
        "                imgElement.style.left = videoRect.left + \"px\";\n",
        "                imgElement.style.width = videoRect.width + \"px\";\n",
        "                imgElement.style.height = videoRect.height + \"px\";\n",
        "                imgElement.src = imgData;\n",
        "            }\n",
        "\n",
        "            var result = await new Promise(function(resolve, reject) {\n",
        "                pendingResolve = resolve;\n",
        "            });\n",
        "            shutdown = false;\n",
        "\n",
        "            return {\n",
        "                'img': result\n",
        "            };\n",
        "        }\n",
        "    '''))"
      ],
      "metadata": {
        "id": "avRo8D8Qru3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criação/Treinamento do Modelo — Detecção de rostos com YOLO**\n",
        "Nesta parte, o modelo YOLO é criado e treinado com um dataset do roboflow"
      ],
      "metadata": {
        "id": "6PaQ1iIyh2Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"COLOQUE_SUA_API_KEY\") # API KEY (Chave pessoal do roboflow)\n",
        "project = rf.workspace(\"COLOQUE_SEU_WORKSPACE\").project(\"mussergesichterzensieren-rlkcm\") # rf.workscape(nome_do_usuário).project(nome_do_projeto)\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "id": "Xa-7z5HQziPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "model.train(\n",
        "     data = \"/content/MusserGesichterZensieren-1/data.yaml\",\n",
        "     epochs = 20,\n",
        "     imgsz = 640,\n",
        " )"
      ],
      "metadata": {
        "id": "sMsqfje1wV38",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loop Principal — Detecção de rostos com YOLO**\n",
        "Nesta parte, o modelo YOLO é integrado ao fluxo da câmera para fazer a detecção de rostos em tempo real."
      ],
      "metadata": {
        "id": "V2qD_3upiNr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@contextmanager\n",
        "def suppress_all_output():\n",
        "    with open(os.devnull, 'w') as devnull:\n",
        "        with redirect_stdout(devnull), redirect_stderr(devnull):\n",
        "            logging.disable(logging.CRITICAL)\n",
        "            try:\n",
        "                yield\n",
        "            finally:\n",
        "                logging.disable(logging.NOTSET)"
      ],
      "metadata": {
        "id": "E1vQ64xzzRX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_stream()\n",
        "\n",
        "\n",
        "label_html = 'Detectando rostos com YOLO...'\n",
        "bbox = ''\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    bbox_array = np.zeros([480, 640, 4], dtype=np.uint8)\n",
        "\n",
        "    with suppress_all_output():\n",
        "        results = model(img)\n",
        "\n",
        "    # Desenha bounding boxes\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "            bbox_array = cv2.rectangle(bbox_array, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "    # Cria overlay com transparência\n",
        "    bbox_array[:, :, 3] = (bbox_array.max(axis=2) > 0).astype(np.uint8) * 255\n",
        "    bbox = bbox_to_bytes(bbox_array)"
      ],
      "metadata": {
        "id": "sdIf575ggjmf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Teste único do modelo treinado (YOLOv8)**\n",
        "\n",
        "Esta célula realiza um **teste simples com imagem estática** para verificar se o modelo YOLO treinado está funcionando corretamente.=\n",
        "---"
      ],
      "metadata": {
        "id": "JRbY13Ybgoa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Dnn86yDdgCM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar(frame):\n",
        "    imagem = cv2.imread(frame)\n",
        "    if imagem is None:\n",
        "        print(f\"Erro: imagem '{frame}' não encontrada.\")\n",
        "        return\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(18, 10)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1pFcsm1TggzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "L36UkGQzDrBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(image_path)\n",
        "results[0].save(filename='predictions.jpg')"
      ],
      "metadata": {
        "id": "mlv4L3O01YFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar('predictions.jpg')"
      ],
      "metadata": {
        "id": "RbZ0cjMVDxY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}